{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe7dcac1-3296-480d-987a-a5405e7e91c5",
   "metadata": {},
   "source": [
    "# Generator of synthetic data to improve fine-tuning with LLaMA and NVIDIA API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967532f5-5148-447b-bb8a-62e591366d6a",
   "metadata": {},
   "source": [
HEAD
    "Running this code requires modifications to main.py script  \n",
 ee2fdd919eedd9cfc38dad1d9e896f2c550a39ec
    "Specifically, I modified the curation in several key ways:\n",
    "1. Allowed longer answers to be included\n",
    "2. Because part of the generation is to create questions for the answers, I decided to filter out the low rating answers\n",
    "3. Also, to improve the overall quality, I only included somewhat well rated questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4e3a11-00f1-4724-a63f-f6d02ca6af86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified curation pipeline function\n",
    "def run_curation_pipeline(\n",
    "    args: Any,\n",
    "    input_dir: str,\n",
    ") -> DocumentDataset:\n",
    "    \"\"\"\n",
    "    Run the curation pipeline on the dataset.\n",
    "\n",
    "    Args:\n",
    "        args: Command-line arguments.\n",
    "        input_dir: The path to the uncurated JSONL file.\n",
    "\n",
    "    Returns:\n",
    "        The resulting dataset.\n",
    "    \"\"\"\n",
    "    orig_dataset = DocumentDataset.read_json(\n",
    "        input_dir, add_filename=True, backend=\"pandas\"\n",
    "    )\n",
    "    dataset = orig_dataset\n",
    "\n",
    "    cpu_curation_steps = Sequential(\n",
    "        [\n",
    "            #\n",
    "            # Modifications\n",
    "            #\n",
    "            # Clean the HTML tags from all the records.\n",
    "            Modify(CleanHTML(), text_field=\"title\"),\n",
    "            Modify(CleanHTML(), text_field=\"question\"),\n",
    "            Modify(CleanHTML(), text_field=\"answer\"),\n",
    "            # Unify the text encoding to Unicode.\n",
    "            Modify(UnicodeReformatter(), text_field=\"title\"),\n",
    "            Modify(UnicodeReformatter(), text_field=\"question\"),\n",
    "            Modify(UnicodeReformatter(), text_field=\"answer\"),\n",
    "            #\n",
    "            # Filtering\n",
    "            #\n",
    "            # Filter out records based on the question or answer word counts.\n",
    "            ScoreFilter(\n",
    "                WordCountFilter(min_words=50, max_words=500),\n",
    "                text_field=\"question\",\n",
    "                score_type=int,\n",
    "            ),\n",
    "            ScoreFilter(\n",
    "                WordCountFilter(min_words=50, max_words=2000),\n",
    "                text_field=\"answer\",\n",
    "                score_type=int,\n",
    "            ),\n",
    "            ScoreFilter(\n",
    "                FilterLowScores(score_threshold=1),\n",
    "                text_field=\"question_score\",\n",
    "                score_type=bool,\n",
    "            ),\n",
    "            ScoreFilter(\n",
    "                FilterLowScores(score_threshold=3),\n",
    "                text_field=\"answer_score\",\n",
    "                score_type=bool,\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Run the CPU curation steps.\n",
    "    dataset = cpu_curation_steps(dataset)\n",
    "\n",
    "    # Define and run the GPU curation steps.\n",
    "    if args.device == \"gpu\":\n",
    "        # Create a text field comprised of the title, question, and answer.\n",
    "        # This field is used for finding semantically similar records and deduping them.\n",
    "        dataset.df[\"text\"] = (\n",
    "            dataset.df[\"title\"]\n",
    "            + \"\\n\"\n",
    "            + dataset.df[\"question\"]\n",
    "            + \"\\n\"\n",
    "            + dataset.df[\"answer\"]\n",
    "        )\n",
    "        dataset.df = dataset.df.to_backend(\"cudf\")\n",
    "        gpu_curation_steps = Sequential(\n",
    "            [\n",
    "                semantic_dedupe,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        dataset = gpu_curation_steps(dataset)\n",
    "        # Delete the text field as it is no longer needed.\n",
    "        del dataset.df[\"text\"]\n",
    "        print('!!!!!!!!!!!', type(dataset.df))\n",
    "        dataset.df = dataset.df.to_backend(\"pandas\")\n",
    "        \n",
    "    print('=======', type(dataset.df))\n",
    "    dataset = dataset.persist()\n",
    "    print('@@@@@@', type(dataset.df))\n",
    "    df = dataset.df.to_backend(\"pandas\")\n",
ee2fdd919eedd9cfc38dad1d9e896f2c550a39ec
    "    orig_len = len(orig_dataset.df)\n",
    "    new_len = 666 #len(df)\n",
    "    print(f\"Original dataset length: {orig_len}\")\n",
    "    print(f\"New dataset length: {new_len}\")\n",
    "\n",
    "    \n",
    "\n",
    "    return df, orig_len, new_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f75d85e-9803-4bf5-a38a-318de9df1555",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Using Nemotron-4 340B:\n",
    "!python main.py \\\n",
    "    --api-key my_api_key \\\n",
    "    --synth-gen-model \"nvidia/llama-3.1-nemotron-70b-instruct\" \\\n",
    "    --synth-gen-rounds 1 \\\n",
 HEAD
    "    --synth-gen-ratio 0.1 \\\n",
 ee2fdd919eedd9cfc38dad1d9e896f2c550a39ec
    "    --device gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4fb90a-0191-484a-af0d-3b8395cd4809",
   "metadata": {},
   "source": [
    "## Inspect what we got  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a328a4d7-41b8-4def-b6f5-d062ba31a4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_synth = \"data/curated/final/law-qa-train.jsonl\"\n",
    "synth_dataset_df = pd.read_json(file_path_synth, orient='records',lines=True)\n",
    "synth_dataset_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46891f9-812d-4da7-a6a0-87c789a352e6",
   "metadata": {},
   "source": [
    "Well that looks good enough"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
